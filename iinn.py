# -*- coding: utf-8 -*-
"""iinn

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BOIGzWWBD3b5Mcr99uFNMzIlu1Y7W_dQ
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
##inline display for graphs and any visualization
# %matplotlib inline

from google.colab import drive #donner l acces a google drive
drive.mount('/content/drive')

dt = pd.read_csv('/content/drive/MyDrive/projet/Ppp - Feuille 1.csv')
dt.head()

dt.shape

##preparing the data
dt.info()

#summarize the state of the data
dt.describe()

#check the missing values
dt.isnull().sum()

#exploratory data analysis
#corrolation
dt.corr()

import seaborn as sns
#to see how the x and y are corrolated
sns.pairplot(dt)

#see the relationship between two faetures
plt.scatter(dt['etat'],dt['Battery Voltage [V]'])
plt.xlabel("etat de la voiture")
plt.ylabel("Battery Voltage [V]")

#see the relationship between two faetures
plt.scatter(dt['etat'],dt['Battery Temperature'])
plt.xlabel("etat de la voiture")
plt.ylabel("Battery Temperature")

import seaborn as sns
sns.regplot(x="etat", y="Battery Voltage [V]", data= dt)

#independant and dependant faetures
X = dt.iloc[:,:-1]
Y = dt.iloc[:,-1]

X.head()

Y

#train test split
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y , test_size = 0.3 , random_state = 42)

X_train

X_test

# standardize the data
from sklearn.preprocessing import StandardScaler
scaler =  StandardScaler()

# tarnsform the data completly to the same scale
X_train = scaler.fit_transform(X_train)

#the test data don t have to know a lot about the training data so we're not gonna use fit
X_test = scaler.transform(X_test)

X_train

#model training
from sklearn.linear_model import LinearRegression

regression = LinearRegression()

#train the model
regression.fit(X_train , Y_train)

# we crate a hyper plane
 #print the coefficients ant the intercept
print(regression.coef_)

print(regression.intercept_)

#on which parameters the model has been trained
regression.get_params()

#prediction with test data
reg_pred = regression.predict(X_test)

#to see all the predictions
reg_pred

#plot a scatter plot for the predictions
plt.scatter(Y_test , reg_pred)

# calcul the error between the y and reg_pred
residuals = Y_test - reg_pred

residuals

# plot this residuals
sns.displot(residuals , kind="kde")

#scatter plot with respect to predictions and residuals the garphe not following any kind of distributions
plt.scatter(reg_pred , residuals)

#to see how the model is bascaly perfroming
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

print(mean_absolute_error(Y_test ,reg_pred))
print(mean_squared_error(Y_test ,reg_pred))
print(np.sqrt(mean_squared_error(Y_test ,reg_pred)))

#check the performance of metrics
from sklearn.metrics import r2_score
score = r2_score(Y_test , reg_pred)
print(score)

#display adjusted r-squared ,, <of 0.72
1 - (1 - score)*(len(Y_test) - 1)/(len(Y_test) - X_test.shape[1] - 1)

# pickling the model file to deployment
import pickle

# Supposons que 'regression' est votre modèle de régression que vous souhaitez enregistrer
# Train and prepare your model here
regression = LinearRegression()
regression.fit(X_train, Y_train)

# Save the model using pickle
with open('regmodel.pkl', 'wb') as model_file:
    pickle.dump(regression, model_file)

pickled_model = pickle.load(open('regmodel.pkl', 'rb'))